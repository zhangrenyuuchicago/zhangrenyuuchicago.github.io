<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Renyu Zhang</title>
  
  <meta name="author" content="Renyu Zhang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Renyu Zhang</name>
              </p>
              <p>I am a graduate student from the University of Chicago. My primary research interest lies in the intersection between healthcare and machine learning. I am particularly interested in medical imaging and scRNA seq.
                My advisor is <a href="https://rgrossman.com/about.html">Robert Grossman</a> and I also work closely with <a href="https://people.cs.uchicago.edu/~aakhan/">Aly Khan</a> and <a href="https://yuxinchen.org/">Yuxin Chen</a>.
		            I got my bachelor degree from Shandong University and master degree from the Institute of Computing Technology of the Chinese Academy of Sciences.
              </p>
              <p style="text-align:center">
                <a href="mailto:zhangr@uchicago.edu">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=-4Hr3l0AAAAJ&hl=en&authuser=1">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/zhangrenyuuchicago">GitHub</a>
              </p>
            </td>
            <td style="padding:2.5%;width:20%;max-width:20%">
              <a href="images/renyu_zhang.jpeg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/renyu_zhang.jpeg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                Selected publications
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/repeated_mnist_learning_curve.png" alt="Boundary_png" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2112.13737">
                <papertitle>BALanCe: Deep Bayesian Active Learning via Equivalence Class Annealing</papertitle>
              </a>
              <br>
              <strong>Renyu Zhang</strong>, Aly Khan, Robert Grossman, Yuxin Chen 
              <br>
              <em>International Conference on Learning Representations (ICLR)</em>, 2023
              <br>
              <p>
        	Active learning has demonstrated data efficiency in many fields. 
		Existing active learning algorithms, especially in the context of batch-mode deep Bayesian active models, rely heavily on the quality of uncertainty estimations of the model, and are often challenging to scale to large batches. 
		In this paper, we propose Batch-BALanCe, a scalable batch-mode active learning algorithm, which combines insights from decision-theoretic active learning, combinatorial information measure, and diversity sampling. 
		At its core, Batch-BALanCe relies on a novel decision-theoretic acquisition function that facilitates differentiation among different equivalence classes. 
		Intuitively, each equivalence class consists of hypotheses (e.g., posterior samples of deep neural networks) with similar predictions, and Batch-BALanCe adaptively adjusts the size of the equivalence classes as learning progresses. 
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/pathcap_clustering.png" alt="Boundary_png" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="http://proceedings.mlr.press/v126/zhang20b.html">
                <papertitle>Evaluating and interpreting caption prediction for histopathology images</papertitle>
              </a>
              <br>
              <strong>Renyu Zhang</strong>, Christopher Weber, Robert Grossman, Aly Khan 
              <br>
              <em>Machine Learning for Healthcare Conference (MLHC)</em>, 2020
              <br>
              <a href="poster/pathcap.pdf">poster</a> / <a href="citation/pathcap.bib">bibtex</a>
              <p>We introduce PathCap, a deep learning multi-scale framework, to predict captions from histopathology images using multi-scale views of whole-slide images. 
                We demonstrate that our framework outperforms a standard baseline caption model on a diverse set of human tissues and provides interpretable contextual cues for understanding predicted captions. 
                Finally, we draw attention to a novel dataset of histopathology images with captions from the Genotype-Tissue Expression (GTEx) project, 
                providing a valuable dataset for the machine learning and healthcare community to benchmark future caption prediction and interpretation methods.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/hierachy.png" alt="Boundary_png" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://ieeexplore.ieee.org/document/9288046">
                <papertitle>Evaluation of Hyperbolic Attention in Histopathology Images</papertitle>
              </a>
              <br>
              <strong>Renyu Zhang</strong>, Aly Khan, Robert Grossman 
              <br>
              <em>The 20th IEEE International Conference on BioInformatics And BioEngineering (BIBE)</em>, 2020
              <br>
              <p>We bring together into a common framework three key ideas â€” multi-scale medical image analysis, the attention mechanism, and hyperbolic embeddings.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
               
            </td>
            <td width="75%" valign="middle">
              <a href="https://ascopubs.org/doi/abs/10.1200/JCO.2020.38.15_suppl.e16097">
                <papertitle>H&E Image-based Consensus Molecular Subtype Classification of Colorectal Cancer Using Weak Labeling</papertitle>
              </a>
              <br>
              Andrew J. Kruger, Lingdao Sha, Madhavi Kannan, Rohan P. Joshi, Benjamin D. Leibowitz, <strong>Renyu Zhang</strong>, Aly A. Khan, Martin Stumpe
              <br>
              <em>ASCO Annual Meeting</em>, 2020
              <br>
              <a href="citation/asco_jco38_e16097.bib">bibtex</a>
              <p>We implemented and trained a novel deep multiple instance learning (MIL) framework that requires only a single label per WSI to identify morphological biomarkers and accelerate CMS classification. </p>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                This webpage uses the template from <a href="https://github.com/jonbarron/jonbarron_website">source code</a>.
                <br>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
